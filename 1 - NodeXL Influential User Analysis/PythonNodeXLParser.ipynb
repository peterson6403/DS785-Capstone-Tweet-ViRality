{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://datasciencedegree.wisconsin.edu/wp-content/themes/data-gulp/images/logo.svg\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project -- NodeXL Data Collection\n",
    "## Matt Peterson - DS 785\n",
    "### 05/06/22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup for file system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gain access to required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import statistics\n",
    "import json\n",
    "import xlrd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set input and output file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output_filename = 'influential_vr_accounts.json'\n",
    "avg_top_items_output_filename = 'users_with_average_top_items.csv'\n",
    "avg_top_items_column_names = (\"USERNAME\", \n",
    "                              \"NAME\",\n",
    "                              \"AVG_IN_DEGREE\", \n",
    "                              \"NUM_DAYS_WITH_TOP_N_IN_DEGREE\",\n",
    "#                               \"AVG_OUT_DEGREE\", \n",
    "#                               \"NUM_DAYS_WITH_TOP_N_OUT_DEGREE\",\n",
    "                              \"AVG_BETWEENNESS\", \n",
    "                              \"NUM_DAYS_WITH_TOP_N_BETWEENNESS\",\n",
    "#                               \"AVG_CLOSENESS\", \n",
    "#                               \"NUM_DAYS_WITH_TOP_N_CLOSENESS\",\n",
    "#                               \"AVG_EIGENVECTOR\", \n",
    "#                               \"NUM_DAYS_WITH_TOP_N_EIGENVECTOR\",\n",
    "                              \"AVG_PAGE_RANK\", \n",
    "                              \"NUM_DAYS_WITH_TOP_N_PAGE_RANK\",\n",
    "                              \"DESCRIPTION\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set input and output directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = cwd = Path.cwd()\n",
    "node_xl_folder = os.path.join(file_dir, 'input')\n",
    "avg_top_items_output_file = os.path.join(file_dir, 'output', avg_top_items_output_filename)\n",
    "json_output_file = os.path.join(file_dir, 'output', json_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Use ```json``` to Read Influential User Dictionary From File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that returns a user dictionary retrieved from JSON file OR an empty dict if none exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_dictionary():\n",
    "    try:\n",
    "        with open(json_output_file) as json_file:\n",
    "            user_dict = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        user_dict = {}\n",
    "    return user_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = get_user_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Use ```pandas``` to Read NodeXL Info from File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that parses the Vertices sheet in NodeXL file, creates a dict, then adds it to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_dict(user_dict, df, measure, file_date):\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        username = row[1]\n",
    "        in_degree = row[2]\n",
    "#         out_degree = row[3]\n",
    "        betweenness = row[3]\n",
    "#         closeness = row[5]\n",
    "#         eigenvector = row[6]\n",
    "        pagerank = row[4]\n",
    "        name = row[5]\n",
    "        description = row[6]\n",
    "        \n",
    "        #update user dictionary for measure value tracking\n",
    "        if username in user_dict:\n",
    "            if not file_date in user_dict[username]['records']:\n",
    "                user_dict[username]['records'][file_date] = {\n",
    "                    'in-degree': in_degree,\n",
    "#                     'out-degree': out_degree,\n",
    "                    'betweenness': betweenness, \n",
    "#                     'closeness': closeness,\n",
    "#                     'eigenvector': eigenvector,\n",
    "                    'pagerank': pagerank\n",
    "                }\n",
    "        else:\n",
    "            user_dict[username] = {\n",
    "                'name': name, \n",
    "                'description': description, \n",
    "                'records': {file_date:\n",
    "                {\n",
    "                    'in-degree': in_degree,\n",
    "#                     'out-degree': out_degree,\n",
    "                    'betweenness': betweenness, \n",
    "#                     'closeness': closeness,\n",
    "#                     'eigenvector': eigenvector,\n",
    "                    'pagerank': pagerank\n",
    "                 }},\n",
    "                'counts': {\n",
    "                    'in-degree': 0,\n",
    "#                     'out-degree': 0,\n",
    "                    'betweenness': 0, \n",
    "#                     'closeness': 0,\n",
    "#                     'eigenvector': 0,\n",
    "                    'pagerank': 0\n",
    "                }}\n",
    "            \n",
    "        user_dict[username]['counts'][measure] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_top_n_users_to_dict_list_by_measure(user_dict, df, measure, top_n, file_date):\n",
    "    sorted_df = df.sort_values(by=measure, ascending=False)\n",
    "    top_n_records = sorted_df.iloc[:top_n]\n",
    "    update_user_dict(user_dict, top_n_records, measure, file_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that:\n",
    "#### 1. Builds a dict list containing each user record having the top N measures in the vertices sheet from each NodeXL file in the directory\n",
    "#### 2. Updates the user dictionary with new records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(text):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \",str(text)).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_dict_with_top_n_items(user_dict, node_xl_folder, top_n):\n",
    "    \n",
    "    for node_xl_file in os.listdir(node_xl_folder):\n",
    "\n",
    "        #get date from filename\n",
    "        file_date = node_xl_file[3:13]\n",
    "\n",
    "        #specify filepath\n",
    "        input_file = os.path.join(file_dir, 'NodeXL Sheets', 'Unprocessed', node_xl_file)\n",
    "\n",
    "        #open NodeXL workbook and store the Vertices sheet as a pandas dataframe\n",
    "        df = pd.read_excel(input_file, sheet_name='Vertices', header=1,\n",
    "                           usecols=['Vertex',\n",
    "                                    'In-Degree',\n",
    "#                                     'Out-Degree',\n",
    "                                    'Betweenness Centrality',\n",
    "#                                     'Closeness Centrality',\n",
    "#                                     'Eigenvector Centrality',\n",
    "                                    'PageRank',\n",
    "                                    'Name',\n",
    "                                    'Description'])\n",
    "        df.columns = ['vertex', \n",
    "                      'in-degree', \n",
    "#                       'out-degree', \n",
    "                      'betweenness',\n",
    "#                       'closeness',\n",
    "#                       'eigenvector', \n",
    "                      'pagerank',\n",
    "                      'name',\n",
    "                      'description']\n",
    "        \n",
    "        #clean up format in description so it can be written to JSON\n",
    "        df['description'] = df['description'].apply(format_text)\n",
    "        df['name'] = df['name'].apply(format_text)\n",
    "                \n",
    "        add_top_n_users_to_dict_list_by_measure(user_dict, df, 'in-degree', top_n, file_date)\n",
    "#         add_top_n_users_to_dict_list_by_measure(user_dict, df, 'out-degree', top_n, file_date)\n",
    "        add_top_n_users_to_dict_list_by_measure(user_dict, df, 'betweenness', top_n, file_date)\n",
    "#         add_top_n_users_to_dict_list_by_measure(user_dict, df, 'closeness', top_n, file_date)\n",
    "#         add_top_n_users_to_dict_list_by_measure(user_dict, df, 'eigenvector', top_n, file_date)\n",
    "        add_top_n_users_to_dict_list_by_measure(user_dict, df, 'pagerank', top_n, file_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that builds a dict list containing each user and their average top item measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measure_average(user_dict, user, measure):\n",
    "    return statistics.mean([records[measure] for date, records in user_dict[user]['records'].items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_top_items_dict_list(user_dict, column_names):\n",
    "    dict_list = []\n",
    "    \n",
    "    for user in user_dict:\n",
    "\n",
    "        dict_list.append(dict(zip(column_names, [user, user_dict[user]['name'],\n",
    "            get_measure_average(user_dict, user, 'in-degree'), user_dict[user]['counts']['in-degree'],\n",
    "#             get_measure_average(user_dict, user, 'out-degree'), user_dict[user]['counts']['out-degree'],\n",
    "            get_measure_average(user_dict, user, 'betweenness'), user_dict[user]['counts']['betweenness'],\n",
    "#             get_measure_average(user_dict, user, 'closeness'), user_dict[user]['counts']['closeness'],\n",
    "#             get_measure_average(user_dict, user, 'eigenvector'), user_dict[user]['counts']['eigenvector'],\n",
    "            get_measure_average(user_dict, user, 'pagerank'), user_dict[user]['counts']['pagerank'],\n",
    "            user_dict[user]['description']])))\n",
    "\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_items = 200\n",
    "\n",
    "#get the dict list containing an instance of each top item measure and update the user dictionary with new instances\n",
    "update_user_dict_with_top_n_items(user_dict, node_xl_folder, top_n_items)\n",
    "\n",
    "#convert the user dictionary into a dict list containing each user and their average top item measures\n",
    "avg_top_items_dict_list = get_avg_top_items_dict_list(user_dict, avg_top_items_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Use ```pandas``` for Data Frame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame for average top items by user\n",
    "avg_top_items_df = pd.DataFrame(avg_top_items_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Export data frames to ```.csv``` file for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to a .csv file \n",
    "avg_top_items_df.to_csv(avg_top_items_output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Export influential VR account dictionary to ```.json``` file for record keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_output_file, \"w\") as outfile:\n",
    "    json.dump(user_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
